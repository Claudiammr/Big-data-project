{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"App\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a40d36499bbcc0a6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load CSV File with Header"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d1f02403b8d20b1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the CSV file with the first row as a header\n",
    "df = spark.read.format(\"csv\").option(\"delimiter\", \",\").option(\"header\", \"true\").load(\"1987.csv\")\n",
    "\n",
    "# Display the columns and the first 15 rows\n",
    "df.show(15, truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29ddc359a0ca93d5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0a44fd-92a8-4c32-9acd-ba2a71946d10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate over all columns in the DataFrame\n",
    "for column in df.columns:\n",
    "    df = df.withColumn(column, when(col(column) == \"NA\", None).otherwise(col(column)))\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baba2d3d-2306-44ab-a74d-095f157c2e07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Counts the number of null values for each column\n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ee0a15-f29b-461b-a029-07104055fa09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mostrar las columnas del DataFrame\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a860ae-2232-471a-9cdf-db8f21a51dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e748d-08b5-4a81-bd26-5eb6b287c520",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "- eliminate unnecesary variables\n",
    "- missing and duplicates values\n",
    "- see correlation\n",
    "- variable transformation\n",
    "- variable creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19529b89-a015-4f2a-a06f-1b699d5b9cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# columns to eliminate\n",
    "columns = [\n",
    "    \"ArrTime\", \n",
    "    \"ActualElapsedTime\", \n",
    "    \"AirTime\", \n",
    "    \"TaxiIn\", \n",
    "    \"Diverted\", \n",
    "    \"CarrierDelay\", \n",
    "    \"WeatherDelay\", \n",
    "    \"NASDelay\", \n",
    "    \"SecurityDelay\", \n",
    "    \"LateAircraftDelay\"\n",
    "]\n",
    "\n",
    "# Eliminate columns\n",
    "df = df.drop(*columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35883cdd-2edc-47ba-a780-e30efd94a0ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a7991-2e7e-4bbc-8b42-060f43af487c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# columns to eliminate\n",
    "columns = [\n",
    "    \"Year\",\n",
    "    \"TailNum\",\n",
    "    \"TaxiOut\",\n",
    "    \"Cancelled\",\n",
    "    \"CancellationCode\"  \n",
    "]\n",
    "\n",
    "# Eliminate columns\n",
    "df = df.drop(*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c332197c-6b29-42bd-9eb4-e791713a1d16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6081fe72-7891-41b4-8766-e90e8691304d",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4648b34a-0027-4839-9895-917333067aef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Contar valores NA por columna\n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "84b193de858d8c34"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Now we check if NA stands for 0. If this value is not present, means that NA was 0."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a66b2cce1bc21e91"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87379505-3215-428c-8bbe-7b734213ae6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "# Filter the DataFrame to keep only rows where ArrDelay is equal to 0\n",
    "filtered_df = df.filter(F.col(\"ArrDelay\") == 0)\n",
    "\n",
    "# Total number of rows in the DataFrame\n",
    "total_rows = df.count()\n",
    "\n",
    "# Check if there are any rows in the filtered DataFrame\n",
    "if filtered_df.count() > 0:\n",
    "    print(\"0 is present in the ArrDelay column \" + str(filtered_df.count()) + \" times out of \" + str(total_rows) + \".\")\n",
    "else:\n",
    "    print(\"0 is not present in the ArrDelay column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df10f9-d1d4-4d2a-b254-828a9caac563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the percentage of null values for each column\n",
    "null_percentage = df.select([(count(when(col(c).isNull(), c)) / total_rows).alias(c) for c in df.columns])\n",
    "\n",
    "# Show the percentage of null values for each column\n",
    "null_percentage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ff12d-d8ee-40b4-aa65-441f1e07c540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop rows with at least one missing value\n",
    "\n",
    "df = df.dropna()\n",
    "dropped_rows = total_rows - df.count()\n",
    "print(\"Dropped \"+ str(dropped_rows)+ \" rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee9a02d-dd7e-43fd-9e56-7c38ef749809",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.printSchema()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d7c298930db6b6a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53d608a-f26a-4550-b9f9-67f0dfc32658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for duplicates and show the results\n",
    "total_rows = df.count()\n",
    "df = df.dropDuplicates()\n",
    "\n",
    "if total_rows - df.count()  > 0:\n",
    "    print(\"There are duplicates in the DataFrame.\")\n",
    "else:\n",
    "    print(\"No duplicates found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882aec0f-ac1f-4104-bb46-2911e52015de",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97708e8b-3193-4499-8ee3-5da8f5c535bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d694f480-0a4f-4bd8-888e-1571a67c45a0",
   "metadata": {},
   "source": [
    "## Variable transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096b53ac-d091-49c6-b989-07346ac53b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to exclude from conversion\n",
    "exclude_columns = ['UniqueCarrier', 'Origin', 'Dest']\n",
    "\n",
    "# Convert all columns to integer type except the ones in exclude_columns\n",
    "for column in df.columns:\n",
    "    if column not in exclude_columns:\n",
    "        df = df.withColumn(column, col(column).cast(\"integer\"))\n",
    "\n",
    "# Display the columns and the first 15 rows to verify the change\n",
    "df.show(15, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Print distinct values for each specified column\n",
    "for column in exclude_columns:\n",
    "    print(f\"Distinct values in column '{column}':\")\n",
    "    distinct_values = df.select(column).distinct().collect()\n",
    "    for value in distinct_values:\n",
    "        print(value[column])\n",
    "    print(\"\\n\")  # Adding a newline for better readability\n",
    "    # Print the number of elements in the distinct_values list\n",
    "    print(f\"Number of distinct values: {len(distinct_values)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14deb4462c6a2749",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "14e90499fbadf24a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.printSchema()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36a1773748b3093d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4dbe2739-b21b-4f0e-a506-ab6d6e834374",
   "metadata": {},
   "source": [
    "## Variable creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abee2f2-cce6-4102-ac53-295b123f6327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b4ea91b-eed6-4c75-a259-574b91ae2856",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044f3cc-7adc-436e-ae23-b23ec00537b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30c8d2ab-1654-4868-9e55-1af0ef9d4ae8",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97493a44-4e9f-447c-b82b-5ba63fbf39be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Close the context"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e715faa356fe098"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bff8e312af807e9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_venv",
   "language": "python",
   "name": "pyspark_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
